{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-22T10:15:11.154417Z",
     "start_time": "2024-09-22T10:15:10.977369600Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PATH2DATA = 'C:/Users/abram/Documents/books/Kopytov/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T10:15:11.169922600Z",
     "start_time": "2024-09-22T10:15:11.159889700Z"
    }
   },
   "id": "1444823403a71c1c",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd591a4c3f8fc2f4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_img():\n",
    "    img = cv2.imread(PATH2DATA + '/train/Original/2_A.png')\n",
    "    return cv2.resize(img, (512, 512))\n",
    "\n",
    "def get_anio():\n",
    "    img = cv2.imread(\"C://Users/abram/Downloads/angio-6/slice.png\",cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img,(512,512))\n",
    "    cv2.imshow('orig',img)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(15,15))\n",
    "    img = clahe.apply(img)\n",
    "    img = cv2.GaussianBlur(img,(7,7),1.4)\n",
    "    edges = cv2.Canny(img,30,105)\n",
    "    cv2.imshow('anio',edges)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "def get_green():\n",
    "    img = get_img()\n",
    "    green = img.copy()\n",
    "    green[:,:,0] = 0\n",
    "    green[:,:,2] = 0\n",
    "    return green\n",
    "\n",
    "#get_anio()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T10:15:11.198737500Z",
     "start_time": "2024-09-22T10:15:11.178918800Z"
    }
   },
   "id": "399572212873e02",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Green channel extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "432665afd3b3ad88"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2draw = get_img()\n",
    "green = img2draw.copy()\n",
    "green[:,:,0] = 0\n",
    "green[:,:,2] = 0\n",
    "cv2.imshow('green', green)\n",
    "cv2.waitKey()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T18:34:44.264163700Z",
     "start_time": "2024-09-21T18:34:40.641831300Z"
    }
   },
   "id": "62c3545f0fd84354",
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porposed method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ff1c2496e754a3a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "green = get_green()\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(15,15))\n",
    "lab = cv2.cvtColor(green,cv2.COLOR_BGR2Lab)\n",
    "lab_planes = list(cv2.split(lab))\n",
    "lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "lab = cv2.merge(lab_planes)\n",
    "green_clahe = cv2.cvtColor(lab,cv2.COLOR_Lab2BGR)\n",
    "# cv2.imshow('green_clahe',green_clahe)\n",
    "# cv2.imshow('green',green)\n",
    "# cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T10:15:11.435181400Z",
     "start_time": "2024-09-22T10:15:11.191210Z"
    }
   },
   "id": "a08870e0993405f8",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_green = cv2.cvtColor(green_clahe,cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray_green, (7, 7), 1.4, 1.4)\n",
    "cv2.imshow('gg',blurred)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T18:10:13.434582Z",
     "start_time": "2024-09-21T18:10:11.125544500Z"
    }
   },
   "id": "a557f4ac6deca457",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(green_clahe, (5, 5), 1.4, 1.4)\n",
    "gx = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)  # Градиент по оси X\n",
    "gy = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)  # Градиент по оси Y\n",
    "M = cv2.magnitude(gx, gy)\n",
    "angle = np.atan(gy/gx)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37efcd1a5ab52e84"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def non_maximum_suppression(gradient_magnitude, gradient_direction):\n",
    "    # Получаем размеры изображения\n",
    "    height, width = gradient_magnitude.shape\n",
    "    # Создаем пустой массив для хранения подавленных значений\n",
    "    suppressed = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "    # Преобразуем углы в градусы\n",
    "    angle = gradient_direction * 180.0 / np.pi\n",
    "    angle[angle < 0] += 180\n",
    "\n",
    "    for y in range(1, height - 1):\n",
    "        for x in range(1, width - 1):\n",
    "            # Определяем направление градиента\n",
    "            q = 255\n",
    "            r = 255\n",
    "\n",
    "            # Угол 0 градусов\n",
    "            if (0 <= angle[y, x] < 22.5) or (157.5 <= angle[y, x] <= 180):\n",
    "                q = gradient_magnitude[y, x + 1]\n",
    "                r = gradient_magnitude[y, x - 1]\n",
    "            # Угол 45 градусов\n",
    "            elif (22.5 <= angle[y, x] < 67.5):\n",
    "                q = gradient_magnitude[y + 1, x - 1]\n",
    "                r = gradient_magnitude[y - 1, x + 1]\n",
    "            # Угол 90 градусов\n",
    "            elif (67.5 <= angle[y, x] < 112.5):\n",
    "                q = gradient_magnitude[y + 1, x]\n",
    "                r = gradient_magnitude[y - 1, x]\n",
    "            # Угол 135 градусов\n",
    "            elif (112.5 <= angle[y, x] < 157.5):\n",
    "                q = gradient_magnitude[y - 1, x - 1]\n",
    "                r = gradient_magnitude[y + 1, x + 1]\n",
    "\n",
    "            # Непосредственное подавление\n",
    "            if gradient_magnitude[y, x] >= q and gradient_magnitude[y, x] >= r:\n",
    "                suppressed[y, x] = gradient_magnitude[y, x]\n",
    "\n",
    "    return suppressed\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T09:15:07.538683800Z",
     "start_time": "2024-09-22T09:15:07.510065Z"
    }
   },
   "id": "f5b073248c7adc6d",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def my_canny(img,lower,upper):\n",
    "    blurred = cv2.GaussianBlur(img, (7, 7), 1.4, 1.4)\n",
    "    green = blurred[:,:,1]\n",
    "    gx = cv2.Sobel(green, cv2.CV_64F, 1, 0, ksize=3)  # Градиент по оси X\n",
    "    gy = cv2.Sobel(green, cv2.CV_64F, 0, 1, ksize=3)  # Градиент по оси Y\n",
    "\n",
    "    magnitude = cv2.magnitude(gx, gy)\n",
    "    magnitude = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    magnitude = np.uint8(magnitude)\n",
    "\n",
    "    cv2.imshow('Sobel Magnitude', magnitude)\n",
    "\n",
    "    M, angle = cv2.cartToPolar(gx, gy, angleInDegrees = True)\n",
    "    height, width, _ = img.shape\n",
    "    supressed = non_maximum_suppression(M,angle)\n",
    "    cv2.imshow('supressed', supressed)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "my_canny(green_clahe,0,0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T09:17:05.963842Z",
     "start_time": "2024-09-22T09:16:55.732852300Z"
    }
   },
   "id": "90c38aa11b81cef0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "# defining the canny detector function \n",
    "\n",
    "# here weak_th and strong_th are thresholds for \n",
    "# double thresholding step \n",
    "def Canny_detector(img, weak_th = None, strong_th = None):\n",
    "\n",
    "    # conversion of image to grayscale \n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Noise reduction step \n",
    "    img = cv2.GaussianBlur(img, (9, 9), 1.4)\n",
    "\n",
    "    # Calculating the gradients \n",
    "    gx = cv2.Sobel(np.float32(img), cv2.CV_64F, 1, 0, 3)\n",
    "    gy = cv2.Sobel(np.float32(img), cv2.CV_64F, 0, 1, 3)\n",
    "\n",
    "    # Conversion of Cartesian coordinates to polar \n",
    "    mag, ang = cv2.cartToPolar(gx, gy, angleInDegrees = True)\n",
    "\n",
    "    # setting the minimum and maximum thresholds \n",
    "    # for double thresholding \n",
    "    mag_max = np.max(mag)\n",
    "    if not weak_th:weak_th = mag_max * 0.1\n",
    "    if not strong_th:strong_th = mag_max * 0.5\n",
    "\n",
    "    # getting the dimensions of the input image \n",
    "    height, width = img.shape\n",
    "\n",
    "    # Looping through every pixel of the grayscale \n",
    "    # image \n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "\n",
    "            grad_ang = ang[i_y, i_x]\n",
    "            grad_ang = abs(grad_ang-180) if abs(grad_ang)>180 else abs(grad_ang)\n",
    "\n",
    "            # selecting the neighbours of the target pixel \n",
    "            # according to the gradient direction \n",
    "            # In the x axis direction \n",
    "            if grad_ang<= 22.5:\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "\n",
    "            # top right (diagonal-1) direction \n",
    "            elif grad_ang>22.5 and grad_ang<=(22.5 + 45):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y + 1\n",
    "\n",
    "            # In y-axis direction \n",
    "            elif grad_ang>(22.5 + 45) and grad_ang<=(22.5 + 90):\n",
    "                neighb_1_x, neighb_1_y = i_x, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x, i_y + 1\n",
    "\n",
    "            # top left (diagonal-2) direction \n",
    "            elif grad_ang>(22.5 + 90) and grad_ang<=(22.5 + 135):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y + 1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y-1\n",
    "\n",
    "            # Now it restarts the cycle \n",
    "            elif grad_ang>(22.5 + 135) and grad_ang<=(22.5 + 180):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "\n",
    "            # Non-maximum suppression step \n",
    "            if width>neighb_1_x>= 0 and height>neighb_1_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_1_y, neighb_1_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "                    continue\n",
    "\n",
    "            if width>neighb_2_x>= 0 and height>neighb_2_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_2_y, neighb_2_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "\n",
    "    weak_ids = np.zeros_like(img)\n",
    "    strong_ids = np.zeros_like(img)\n",
    "    ids = np.zeros_like(img)\n",
    "    \n",
    "   # cv2.imshow('non max',mag)\n",
    "    \n",
    "    # double thresholding step \n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "\n",
    "            grad_mag = mag[i_y, i_x]\n",
    "            \n",
    "            if grad_mag<weak_th:\n",
    "                mag[i_y, i_x]= 0\n",
    "            elif strong_th>grad_mag>= weak_th:\n",
    "                ids[i_y, i_x]= 1\n",
    "            else:\n",
    "                ids[i_y, i_x]= 2\n",
    "    \n",
    "    cv2.imshow('own_canny.png', mag)\n",
    "    final_edges = np.copy(mag)\n",
    "    \n",
    "    idx = 4\n",
    "    for i in range(idx,ids.shape[0]-idx):\n",
    "        for j in range(idx,ids.shape[1]-idx):\n",
    "            if ids[i,j] != 0:\n",
    "                if np.any(ids[i-idx:i+idx+1,j-idx:j+idx+1] != 1):\n",
    "                    final_edges[i,j] = 255\n",
    "                else:\n",
    "                    final_edges[i,j] = 0\n",
    "    \n",
    "    #cv2.imshow('trass',final_edges)\n",
    "    return mag\n",
    "\n",
    "# calling the designed function for \n",
    "# finding edges \n",
    "canny_img = Canny_detector(green_clahe[:,:,1],20,80)\n",
    "\n",
    "# blurred = cv2.GaussianBlur(green_clahe,(5,5),1.4)\n",
    "# blurred_edges = cv2.Canny(blurred[:,:,1],20,80)\n",
    "# cv2.imwrite('blurred_canny_20_80.png',blurred_edges)\n",
    "# \n",
    "# blurred_edges = cv2.Canny(blurred[:,:,1],20,55)\n",
    "# cv2.imwrite('blurred_canny_20_55.png',blurred_edges)\n",
    "# \n",
    "# blurred_edges = cv2.Canny(blurred[:,:,1],20,35)\n",
    "# cv2.imwrite('blurred_canny_20_35.png',blurred_edges)\n",
    "\n",
    "\n",
    "#edges = cv2.Canny(green_clahe[:,:,1],20,80)\n",
    "#cv2.imshow('canny',edges)\n",
    "#cv2.imshow('custom_canny',canny_img)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T11:41:53.689588900Z",
     "start_time": "2024-09-22T11:41:47.094424200Z"
    }
   },
   "id": "3bbcd6296b742f2b",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T10:30:44.689155600Z",
     "start_time": "2024-09-22T10:30:36.028620Z"
    }
   },
   "id": "99f118d6266d7186",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2draw = get_img()\n",
    "gray = cv2.cvtColor(img2draw, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Original', gray)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T08:08:14.832816500Z",
     "start_time": "2024-09-21T08:08:13.043356900Z"
    }
   },
   "id": "fee11b76bdddd996",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = cv2.adaptiveThreshold(green_clahe[:,:,1], 250, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,53,10)\n",
    "cv2.imwrite('adaptive_thresh.png',thresh)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T11:40:21.560816Z",
     "start_time": "2024-09-22T11:40:21.519992Z"
    }
   },
   "id": "bf3c85f76e6300aa",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adaptive threshold"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67e431cfa5333410"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2draw = get_img()\n",
    "thresh = cv2.adaptiveThreshold(green_clahe[:,:,1], 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,53,10)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img2draw, contours, -1,(255,0,0),2)\n",
    "cv2.imshow('test',img2draw)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T11:35:23.115752300Z",
     "start_time": "2024-09-22T11:35:17.160514300Z"
    }
   },
   "id": "992fb71eb01d7a12",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "Canny"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95e3feda891b4795"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2draw = get_img()\n",
    "blurred = cv2.GaussianBlur(green, (5, 5), 0)\n",
    "#thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,43,13)\n",
    "edges = cv2.Canny(blurred,25,55)\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img2draw, contours, -1,(255,0,0),2)\n",
    "cv2.imshow('canny',edges)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T10:39:33.442547800Z",
     "start_time": "2024-09-21T10:39:31.618364100Z"
    }
   },
   "id": "6dd0b39d6153e278",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2draw = get_img()\n",
    "edges = cv2.Canny(img,100,200)\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img2draw, contours, -1,(255,0,0),2)\n",
    "cv2.imshow('canny',edges)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T08:07:48.974430800Z",
     "start_time": "2024-09-21T08:07:46.847602100Z"
    }
   },
   "id": "22fedd7b604242fa",
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sobel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60a338da136e0d78"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sobel_combined = np.uint8(np.absolute(sobel_combined))\n",
    "img2draw = img.copy()\n",
    "thresh = cv2.adaptiveThreshold(sobel_combined,255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,53,10)\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img2draw, contours, -1,(255,0,0),2)\n",
    "cv2.imshow('sobel',img2draw)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T10:26:37.389216700Z",
     "start_time": "2024-09-21T10:26:35.003146100Z"
    }
   },
   "id": "2cafb5025ec3dd01",
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
